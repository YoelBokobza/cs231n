{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZf1iwEq46r",
        "outputId": "917380a0-6309-4e80-de39-9a7a23ce2783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/CS231n_assignment1/cs231n/datasets\n",
            "/content/drive/My Drive/CS231n_assignment1\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
        "FOLDERNAME = 'CS231n_assignment1'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# This downloads the CIFAR-10 dataset to your Drive\n",
        "# if it doesn't already exist.\n",
        "%cd drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
        "!bash get_datasets.sh\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-title"
        ],
        "id": "MkRMCcs2q46v"
      },
      "source": [
        "# Softmax exercise\n",
        "\n",
        "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
        "\n",
        "This exercise is analogous to the SVM exercise. You will:\n",
        "\n",
        "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
        "- implement the fully-vectorized expression for its **analytic gradient**\n",
        "- **check your implementation** with numerical gradient\n",
        "- use a validation set to **tune the learning rate and regularization** strength\n",
        "- **optimize** the loss function with **SGD**\n",
        "- **visualize** the final learned weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "id": "JhZQ_u7uq46z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from cs231n.data_utils import load_CIFAR10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [
          "pdf-ignore"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp4zNFE0q460",
        "outputId": "6a88745b-4b87-4b9c-89bf-539d59028727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape:  (49000, 3073)\n",
            "Train labels shape:  (49000,)\n",
            "Validation data shape:  (1000, 3073)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (1000, 3073)\n",
            "Test labels shape:  (1000,)\n",
            "dev data shape:  (500, 3073)\n",
            "dev labels shape:  (500,)\n"
          ]
        }
      ],
      "source": [
        "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for the linear classifier. These are the same steps as we used for the\n",
        "    SVM, but condensed to a single function.  \n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
        "    \n",
        "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
        "    try:\n",
        "       del X_train, y_train\n",
        "       del X_test, y_test\n",
        "       print('Clear previously loaded data.')\n",
        "    except:\n",
        "       pass\n",
        "\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "    \n",
        "    # subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
        "    X_dev = X_train[mask]\n",
        "    y_dev = y_train[mask]\n",
        "    \n",
        "    # Preprocessing: reshape the image data into rows\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
        "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
        "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
        "    \n",
        "    # Normalize the data: subtract the mean image\n",
        "    mean_image = np.mean(X_train, axis = 0)\n",
        "    X_train -= mean_image\n",
        "    X_val -= mean_image\n",
        "    X_test -= mean_image\n",
        "    X_dev -= mean_image\n",
        "    \n",
        "    # add bias dimension and transform into columns\n",
        "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
        "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
        "\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)\n",
        "print('dev data shape: ', X_dev.shape)\n",
        "print('dev labels shape: ', y_dev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iynjdBsAq463"
      },
      "source": [
        "## Softmax Classifier\n",
        "\n",
        "Your code for this section will all be written inside `cs231n/classifiers/softmax.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQN-3nNtq464",
        "outputId": "7c0ce055-4e72-4693-f02a-b367916f5dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.291710\n",
            "sanity check: 2.302585\n"
          ]
        }
      ],
      "source": [
        "# First implement the naive softmax loss function with nested loops.\n",
        "# Open the file cs231n/classifiers/softmax.py and implement the\n",
        "# softmax_loss_naive function.\n",
        "\n",
        "from cs231n.classifiers.softmax import softmax_loss_naive\n",
        "import time\n",
        "\n",
        "# Generate a random softmax weight matrix and use it to compute the loss.\n",
        "W = np.random.randn(3073, 10) * 0.0001\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
        "print('loss: %f' % loss)\n",
        "print('sanity check: %f' % (-np.log(0.1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-inline"
        ],
        "id": "xTvLvbNLq465"
      },
      "source": [
        "**Inline Question 1**\n",
        "\n",
        "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
        "\n",
        "$\\color{blue}{\\textit Your Answer:}$ *Fill this in* \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TeSahpnq467",
        "outputId": "8d95e92a-c028-42e8-952d-6df5639bbe1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numerical: -0.832693 analytic: -0.832693, relative error: 6.423559e-09\n",
            "numerical: 0.126017 analytic: 0.126017, relative error: 2.893863e-07\n",
            "numerical: 5.119857 analytic: 5.119857, relative error: 1.576177e-08\n",
            "numerical: -3.127512 analytic: -3.127512, relative error: 8.061824e-10\n",
            "numerical: -0.584366 analytic: -0.584366, relative error: 3.120541e-08\n",
            "numerical: -1.723285 analytic: -1.723285, relative error: 1.791551e-08\n",
            "numerical: -1.335225 analytic: -1.335225, relative error: 3.964878e-08\n",
            "numerical: 0.147375 analytic: 0.147375, relative error: 2.284451e-07\n",
            "numerical: 0.159694 analytic: 0.159694, relative error: 1.109321e-07\n",
            "numerical: -1.546004 analytic: -1.546004, relative error: 3.622655e-08\n",
            "numerical: 0.817337 analytic: 0.817337, relative error: 3.314904e-08\n",
            "numerical: -3.499367 analytic: -3.499367, relative error: 2.782243e-08\n",
            "numerical: 0.178536 analytic: 0.178536, relative error: 7.092218e-09\n",
            "numerical: 2.085020 analytic: 2.085020, relative error: 2.650302e-08\n",
            "numerical: -1.587255 analytic: -1.587255, relative error: 4.095382e-08\n",
            "numerical: -0.658020 analytic: -0.658020, relative error: 6.624979e-08\n",
            "numerical: -0.851789 analytic: -0.851789, relative error: 3.930833e-08\n",
            "numerical: 1.913186 analytic: 1.913186, relative error: 1.029135e-08\n",
            "numerical: -0.035154 analytic: -0.035154, relative error: 6.112452e-07\n",
            "numerical: -0.923907 analytic: -0.923907, relative error: 4.217006e-08\n"
          ]
        }
      ],
      "source": [
        "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
        "# version of the gradient that uses nested loops.\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
        "\n",
        "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
        "# The numeric gradient should be close to the analytic gradient.\n",
        "from cs231n.gradient_check import grad_check_sparse\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
        "\n",
        "# similar to SVM case, do another gradient check with regularization\n",
        "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
        "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
        "grad_numerical = grad_check_sparse(f, W, grad, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OPqUtED2q468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e6a050-0b47-4eea-d0ea-7fbd7085f8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "naive loss: 2.291710e+00 computed in 0.389232s\n",
            "vectorized loss: 2.291710e+00 computed in 0.008142s\n",
            "Loss difference: 0.000000\n",
            "Gradient difference: 0.000000\n"
          ]
        }
      ],
      "source": [
        "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
        "# implement a vectorized version in softmax_loss_vectorized.\n",
        "# The two versions should compute the same results, but the vectorized version should be\n",
        "# much faster.\n",
        "tic = time.time()\n",
        "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
        "\n",
        "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
        "tic = time.time()\n",
        "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
        "toc = time.time()\n",
        "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
        "\n",
        "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
        "# of the gradient.\n",
        "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
        "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
        "print('Gradient difference: %f' % grad_difference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tuning",
        "tags": [
          "code"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec44150-6c26-4fa7-dc34-37203c48fb63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 / 1900: loss 161.672845\n",
            "iteration 100 / 1900: loss 158.532329\n",
            "iteration 200 / 1900: loss 154.592644\n",
            "iteration 300 / 1900: loss 151.501508\n",
            "iteration 400 / 1900: loss 148.375477\n",
            "iteration 500 / 1900: loss 145.116222\n",
            "iteration 600 / 1900: loss 142.670963\n",
            "iteration 700 / 1900: loss 139.413577\n",
            "iteration 800 / 1900: loss 136.524109\n",
            "iteration 900 / 1900: loss 133.688463\n",
            "iteration 1000 / 1900: loss 131.256325\n",
            "iteration 1100 / 1900: loss 128.233338\n",
            "iteration 1200 / 1900: loss 125.940941\n",
            "iteration 1300 / 1900: loss 123.543254\n",
            "iteration 1400 / 1900: loss 121.032622\n",
            "iteration 1500 / 1900: loss 118.465575\n",
            "iteration 1600 / 1900: loss 116.179131\n",
            "iteration 1700 / 1900: loss 113.753199\n",
            "iteration 1800 / 1900: loss 111.828009\n",
            "iteration 0 / 1900: loss 312.197709\n",
            "iteration 100 / 1900: loss 299.895895\n",
            "iteration 200 / 1900: loss 287.933788\n",
            "iteration 300 / 1900: loss 276.442313\n",
            "iteration 400 / 1900: loss 265.684474\n",
            "iteration 500 / 1900: loss 255.266016\n",
            "iteration 600 / 1900: loss 245.325613\n",
            "iteration 700 / 1900: loss 235.329188\n",
            "iteration 800 / 1900: loss 226.142834\n",
            "iteration 900 / 1900: loss 217.171082\n",
            "iteration 1000 / 1900: loss 208.613274\n",
            "iteration 1100 / 1900: loss 200.744817\n",
            "iteration 1200 / 1900: loss 193.070468\n",
            "iteration 1300 / 1900: loss 185.375849\n",
            "iteration 1400 / 1900: loss 177.800669\n",
            "iteration 1500 / 1900: loss 170.769840\n",
            "iteration 1600 / 1900: loss 164.151444\n",
            "iteration 1700 / 1900: loss 157.984272\n",
            "iteration 1800 / 1900: loss 151.746658\n",
            "iteration 0 / 1900: loss 769.774773\n",
            "iteration 100 / 1900: loss 696.035062\n",
            "iteration 200 / 1900: loss 629.572651\n",
            "iteration 300 / 1900: loss 569.481364\n",
            "iteration 400 / 1900: loss 515.134541\n",
            "iteration 500 / 1900: loss 466.660763\n",
            "iteration 600 / 1900: loss 421.785388\n",
            "iteration 700 / 1900: loss 381.987443\n",
            "iteration 800 / 1900: loss 345.494760\n",
            "iteration 900 / 1900: loss 312.911192\n",
            "iteration 1000 / 1900: loss 282.993324\n",
            "iteration 1100 / 1900: loss 256.475228\n",
            "iteration 1200 / 1900: loss 231.931709\n",
            "iteration 1300 / 1900: loss 210.238540\n",
            "iteration 1400 / 1900: loss 190.245676\n",
            "iteration 1500 / 1900: loss 172.193762\n",
            "iteration 1600 / 1900: loss 156.017162\n",
            "iteration 1700 / 1900: loss 141.420789\n",
            "iteration 1800 / 1900: loss 128.015064\n",
            "iteration 0 / 1900: loss 1060.365822\n",
            "iteration 100 / 1900: loss 921.444632\n",
            "iteration 200 / 1900: loss 801.172746\n",
            "iteration 300 / 1900: loss 696.543781\n",
            "iteration 400 / 1900: loss 605.550675\n",
            "iteration 500 / 1900: loss 526.289794\n",
            "iteration 600 / 1900: loss 457.648697\n",
            "iteration 700 / 1900: loss 398.195944\n",
            "iteration 800 / 1900: loss 346.272198\n",
            "iteration 900 / 1900: loss 300.995717\n",
            "iteration 1000 / 1900: loss 261.979621\n",
            "iteration 1100 / 1900: loss 228.003994\n",
            "iteration 1200 / 1900: loss 198.534299\n",
            "iteration 1300 / 1900: loss 172.759963\n",
            "iteration 1400 / 1900: loss 150.436681\n",
            "iteration 1500 / 1900: loss 130.919579\n",
            "iteration 1600 / 1900: loss 114.145292\n",
            "iteration 1700 / 1900: loss 99.480263\n",
            "iteration 1800 / 1900: loss 86.696381\n",
            "iteration 0 / 1900: loss 1544.250749\n",
            "iteration 100 / 1900: loss 1264.144749\n",
            "iteration 200 / 1900: loss 1035.063346\n",
            "iteration 300 / 1900: loss 847.056606\n",
            "iteration 400 / 1900: loss 693.569446\n",
            "iteration 500 / 1900: loss 568.031660\n",
            "iteration 600 / 1900: loss 465.412098\n",
            "iteration 700 / 1900: loss 381.189698\n",
            "iteration 800 / 1900: loss 312.364585\n",
            "iteration 900 / 1900: loss 255.963563\n",
            "iteration 1000 / 1900: loss 209.898437\n",
            "iteration 1100 / 1900: loss 172.145397\n",
            "iteration 1200 / 1900: loss 141.253832\n",
            "iteration 1300 / 1900: loss 116.024565\n",
            "iteration 1400 / 1900: loss 95.312860\n",
            "iteration 1500 / 1900: loss 78.369155\n",
            "iteration 1600 / 1900: loss 64.575878\n",
            "iteration 1700 / 1900: loss 53.256991\n",
            "iteration 1800 / 1900: loss 43.957834\n",
            "iteration 0 / 1900: loss 161.376346\n",
            "iteration 100 / 1900: loss 130.000935\n",
            "iteration 200 / 1900: loss 106.213229\n",
            "iteration 300 / 1900: loss 86.995148\n",
            "iteration 400 / 1900: loss 71.254424\n",
            "iteration 500 / 1900: loss 58.687587\n",
            "iteration 600 / 1900: loss 48.454442\n",
            "iteration 700 / 1900: loss 39.775263\n",
            "iteration 800 / 1900: loss 32.851772\n",
            "iteration 900 / 1900: loss 27.307433\n",
            "iteration 1000 / 1900: loss 22.641633\n",
            "iteration 1100 / 1900: loss 18.890054\n",
            "iteration 1200 / 1900: loss 15.781880\n",
            "iteration 1300 / 1900: loss 13.104377\n",
            "iteration 1400 / 1900: loss 11.220066\n",
            "iteration 1500 / 1900: loss 9.443299\n",
            "iteration 1600 / 1900: loss 8.103075\n",
            "iteration 1700 / 1900: loss 6.990039\n",
            "iteration 1800 / 1900: loss 6.075673\n",
            "iteration 0 / 1900: loss 315.261842\n",
            "iteration 100 / 1900: loss 209.978193\n",
            "iteration 200 / 1900: loss 141.033900\n",
            "iteration 300 / 1900: loss 95.039220\n",
            "iteration 400 / 1900: loss 64.079865\n",
            "iteration 500 / 1900: loss 43.605725\n",
            "iteration 600 / 1900: loss 29.727181\n",
            "iteration 700 / 1900: loss 20.604103\n",
            "iteration 800 / 1900: loss 14.445729\n",
            "iteration 900 / 1900: loss 10.353180\n",
            "iteration 1000 / 1900: loss 7.536021\n",
            "iteration 1100 / 1900: loss 5.715721\n",
            "iteration 1200 / 1900: loss 4.511113\n",
            "iteration 1300 / 1900: loss 3.705806\n",
            "iteration 1400 / 1900: loss 3.085653\n",
            "iteration 1500 / 1900: loss 2.725972\n",
            "iteration 1600 / 1900: loss 2.536113\n",
            "iteration 1700 / 1900: loss 2.287109\n",
            "iteration 1800 / 1900: loss 2.257684\n",
            "iteration 0 / 1900: loss 780.067940\n",
            "iteration 100 / 1900: loss 286.533506\n",
            "iteration 200 / 1900: loss 106.255344\n",
            "iteration 300 / 1900: loss 40.174480\n",
            "iteration 400 / 1900: loss 15.994968\n",
            "iteration 500 / 1900: loss 7.179402\n",
            "iteration 600 / 1900: loss 3.931209\n",
            "iteration 700 / 1900: loss 2.775106\n",
            "iteration 800 / 1900: loss 2.302670\n",
            "iteration 900 / 1900: loss 2.204441\n",
            "iteration 1000 / 1900: loss 2.121595\n",
            "iteration 1100 / 1900: loss 2.026526\n",
            "iteration 1200 / 1900: loss 2.086843\n",
            "iteration 1300 / 1900: loss 2.125556\n",
            "iteration 1400 / 1900: loss 2.139591\n",
            "iteration 1500 / 1900: loss 2.074110\n",
            "iteration 1600 / 1900: loss 2.068527\n",
            "iteration 1700 / 1900: loss 2.079188\n",
            "iteration 1800 / 1900: loss 2.122449\n",
            "iteration 0 / 1900: loss 1079.009529\n",
            "iteration 100 / 1900: loss 265.480861\n",
            "iteration 200 / 1900: loss 66.443370\n",
            "iteration 300 / 1900: loss 17.933646\n",
            "iteration 400 / 1900: loss 5.983987\n",
            "iteration 500 / 1900: loss 3.016780\n",
            "iteration 600 / 1900: loss 2.351988\n",
            "iteration 700 / 1900: loss 2.221932\n",
            "iteration 800 / 1900: loss 2.100190\n",
            "iteration 900 / 1900: loss 2.132573\n",
            "iteration 1000 / 1900: loss 2.149893\n",
            "iteration 1100 / 1900: loss 2.092694\n",
            "iteration 1200 / 1900: loss 2.124708\n",
            "iteration 1300 / 1900: loss 2.141424\n",
            "iteration 1400 / 1900: loss 2.137177\n",
            "iteration 1500 / 1900: loss 2.140788\n",
            "iteration 1600 / 1900: loss 2.128573\n",
            "iteration 1700 / 1900: loss 2.120621\n",
            "iteration 1800 / 1900: loss 2.174071\n",
            "iteration 0 / 1900: loss 1527.010587\n",
            "iteration 100 / 1900: loss 205.625442\n",
            "iteration 200 / 1900: loss 29.387524\n",
            "iteration 300 / 1900: loss 5.777892\n",
            "iteration 400 / 1900: loss 2.594054\n",
            "iteration 500 / 1900: loss 2.216875\n",
            "iteration 600 / 1900: loss 2.156442\n",
            "iteration 700 / 1900: loss 2.193254\n",
            "iteration 800 / 1900: loss 2.139299\n",
            "iteration 900 / 1900: loss 2.121596\n",
            "iteration 1000 / 1900: loss 2.099401\n",
            "iteration 1100 / 1900: loss 2.215266\n",
            "iteration 1200 / 1900: loss 2.135664\n",
            "iteration 1300 / 1900: loss 2.156334\n",
            "iteration 1400 / 1900: loss 2.158578\n",
            "iteration 1500 / 1900: loss 2.139123\n",
            "iteration 1600 / 1900: loss 2.129934\n",
            "iteration 1700 / 1900: loss 2.162938\n",
            "iteration 1800 / 1900: loss 2.166057\n",
            "iteration 0 / 1900: loss 159.075877\n",
            "iteration 100 / 1900: loss 58.303330\n",
            "iteration 200 / 1900: loss 22.493728\n",
            "iteration 300 / 1900: loss 9.393691\n",
            "iteration 400 / 1900: loss 4.786214\n",
            "iteration 500 / 1900: loss 2.965762\n",
            "iteration 600 / 1900: loss 2.269452\n",
            "iteration 700 / 1900: loss 2.016768\n",
            "iteration 800 / 1900: loss 2.043662\n",
            "iteration 900 / 1900: loss 1.958223\n",
            "iteration 1000 / 1900: loss 1.948953\n",
            "iteration 1100 / 1900: loss 1.993015\n",
            "iteration 1200 / 1900: loss 1.966015\n",
            "iteration 1300 / 1900: loss 1.904709\n",
            "iteration 1400 / 1900: loss 1.915948\n",
            "iteration 1500 / 1900: loss 2.006869\n",
            "iteration 1600 / 1900: loss 1.906736\n",
            "iteration 1700 / 1900: loss 2.019850\n",
            "iteration 1800 / 1900: loss 2.010753\n",
            "iteration 0 / 1900: loss 307.055490\n",
            "iteration 100 / 1900: loss 42.238135\n",
            "iteration 200 / 1900: loss 7.339661\n",
            "iteration 300 / 1900: loss 2.718727\n",
            "iteration 400 / 1900: loss 2.102769\n",
            "iteration 500 / 1900: loss 1.983598\n",
            "iteration 600 / 1900: loss 2.030858\n",
            "iteration 700 / 1900: loss 2.022840\n",
            "iteration 800 / 1900: loss 2.043985\n",
            "iteration 900 / 1900: loss 1.975389\n",
            "iteration 1000 / 1900: loss 1.964354\n",
            "iteration 1100 / 1900: loss 2.065659\n",
            "iteration 1200 / 1900: loss 2.008950\n",
            "iteration 1300 / 1900: loss 1.972185\n",
            "iteration 1400 / 1900: loss 2.045013\n",
            "iteration 1500 / 1900: loss 2.031031\n",
            "iteration 1600 / 1900: loss 1.995998\n",
            "iteration 1700 / 1900: loss 2.046796\n",
            "iteration 1800 / 1900: loss 2.002699\n",
            "iteration 0 / 1900: loss 775.800041\n",
            "iteration 100 / 1900: loss 6.832910\n",
            "iteration 200 / 1900: loss 2.095028\n",
            "iteration 300 / 1900: loss 2.019391\n",
            "iteration 400 / 1900: loss 2.132491\n",
            "iteration 500 / 1900: loss 2.110322\n",
            "iteration 600 / 1900: loss 2.104204\n",
            "iteration 700 / 1900: loss 2.071196\n",
            "iteration 800 / 1900: loss 2.043360\n",
            "iteration 900 / 1900: loss 2.103995\n",
            "iteration 1000 / 1900: loss 2.075619\n",
            "iteration 1100 / 1900: loss 2.112344\n",
            "iteration 1200 / 1900: loss 2.106828\n",
            "iteration 1300 / 1900: loss 2.092176\n",
            "iteration 1400 / 1900: loss 2.149143\n",
            "iteration 1500 / 1900: loss 2.024681\n",
            "iteration 1600 / 1900: loss 2.069704\n",
            "iteration 1700 / 1900: loss 2.087067\n",
            "iteration 1800 / 1900: loss 2.123400\n",
            "iteration 0 / 1900: loss 1093.118434\n",
            "iteration 100 / 1900: loss 3.010831\n",
            "iteration 200 / 1900: loss 2.133761\n",
            "iteration 300 / 1900: loss 2.111100\n",
            "iteration 400 / 1900: loss 2.100873\n",
            "iteration 500 / 1900: loss 2.115107\n",
            "iteration 600 / 1900: loss 2.137730\n",
            "iteration 700 / 1900: loss 2.139732\n",
            "iteration 800 / 1900: loss 2.110421\n",
            "iteration 900 / 1900: loss 2.055018\n",
            "iteration 1000 / 1900: loss 2.115084\n",
            "iteration 1100 / 1900: loss 2.153218\n",
            "iteration 1200 / 1900: loss 2.147890\n",
            "iteration 1300 / 1900: loss 2.093604\n",
            "iteration 1400 / 1900: loss 2.131098\n",
            "iteration 1500 / 1900: loss 2.094895\n",
            "iteration 1600 / 1900: loss 2.144612\n",
            "iteration 1700 / 1900: loss 2.119919\n",
            "iteration 1800 / 1900: loss 2.110219\n",
            "iteration 0 / 1900: loss 1512.263156\n",
            "iteration 100 / 1900: loss 2.176070\n",
            "iteration 200 / 1900: loss 2.127620\n",
            "iteration 300 / 1900: loss 2.137715\n",
            "iteration 400 / 1900: loss 2.154745\n",
            "iteration 500 / 1900: loss 2.184509\n",
            "iteration 600 / 1900: loss 2.154794\n",
            "iteration 700 / 1900: loss 2.151963\n",
            "iteration 800 / 1900: loss 2.114849\n",
            "iteration 900 / 1900: loss 2.108179\n",
            "iteration 1000 / 1900: loss 2.136201\n",
            "iteration 1100 / 1900: loss 2.110464\n",
            "iteration 1200 / 1900: loss 2.117264\n",
            "iteration 1300 / 1900: loss 2.131404\n",
            "iteration 1400 / 1900: loss 2.185488\n",
            "iteration 1500 / 1900: loss 2.163779\n",
            "iteration 1600 / 1900: loss 2.198069\n",
            "iteration 1700 / 1900: loss 2.167110\n",
            "iteration 1800 / 1900: loss 2.144503\n",
            "iteration 0 / 1900: loss 159.189002\n",
            "iteration 100 / 1900: loss 22.210120\n",
            "iteration 200 / 1900: loss 4.623099\n",
            "iteration 300 / 1900: loss 2.378341\n",
            "iteration 400 / 1900: loss 2.056863\n",
            "iteration 500 / 1900: loss 1.986945\n",
            "iteration 600 / 1900: loss 1.970355\n",
            "iteration 700 / 1900: loss 1.930775\n",
            "iteration 800 / 1900: loss 1.961898\n",
            "iteration 900 / 1900: loss 1.963541\n",
            "iteration 1000 / 1900: loss 2.025247\n",
            "iteration 1100 / 1900: loss 1.899783\n",
            "iteration 1200 / 1900: loss 2.003429\n",
            "iteration 1300 / 1900: loss 1.840919\n",
            "iteration 1400 / 1900: loss 2.048050\n",
            "iteration 1500 / 1900: loss 1.926729\n",
            "iteration 1600 / 1900: loss 2.017635\n",
            "iteration 1700 / 1900: loss 1.972884\n",
            "iteration 1800 / 1900: loss 1.927083\n",
            "iteration 0 / 1900: loss 313.538053\n",
            "iteration 100 / 1900: loss 7.377555\n",
            "iteration 200 / 1900: loss 2.123381\n",
            "iteration 300 / 1900: loss 2.059574\n",
            "iteration 400 / 1900: loss 1.968103\n",
            "iteration 500 / 1900: loss 2.031264\n",
            "iteration 600 / 1900: loss 1.982301\n",
            "iteration 700 / 1900: loss 2.044205\n",
            "iteration 800 / 1900: loss 2.095688\n",
            "iteration 900 / 1900: loss 1.995729\n",
            "iteration 1000 / 1900: loss 1.999637\n",
            "iteration 1100 / 1900: loss 2.035569\n",
            "iteration 1200 / 1900: loss 2.029612\n",
            "iteration 1300 / 1900: loss 1.939650\n",
            "iteration 1400 / 1900: loss 2.041779\n",
            "iteration 1500 / 1900: loss 2.057219\n",
            "iteration 1600 / 1900: loss 1.953511\n",
            "iteration 1700 / 1900: loss 1.925914\n",
            "iteration 1800 / 1900: loss 1.925799\n",
            "iteration 0 / 1900: loss 777.667197\n",
            "iteration 100 / 1900: loss 2.151409\n",
            "iteration 200 / 1900: loss 2.191489\n",
            "iteration 300 / 1900: loss 2.115721\n",
            "iteration 400 / 1900: loss 2.090621\n",
            "iteration 500 / 1900: loss 2.098412\n",
            "iteration 600 / 1900: loss 2.068254\n",
            "iteration 700 / 1900: loss 2.128098\n",
            "iteration 800 / 1900: loss 2.078246\n",
            "iteration 900 / 1900: loss 2.107240\n",
            "iteration 1000 / 1900: loss 2.095619\n",
            "iteration 1100 / 1900: loss 2.068326\n",
            "iteration 1200 / 1900: loss 2.135100\n",
            "iteration 1300 / 1900: loss 2.068977\n",
            "iteration 1400 / 1900: loss 2.140300\n",
            "iteration 1500 / 1900: loss 2.111298\n",
            "iteration 1600 / 1900: loss 2.098761\n",
            "iteration 1700 / 1900: loss 2.099845\n",
            "iteration 1800 / 1900: loss 2.059074\n",
            "iteration 0 / 1900: loss 1078.989020\n",
            "iteration 100 / 1900: loss 2.120390\n",
            "iteration 200 / 1900: loss 2.083576\n",
            "iteration 300 / 1900: loss 2.117300\n",
            "iteration 400 / 1900: loss 2.116541\n",
            "iteration 500 / 1900: loss 2.132690\n",
            "iteration 600 / 1900: loss 2.139445\n",
            "iteration 700 / 1900: loss 2.094463\n",
            "iteration 800 / 1900: loss 2.150716\n",
            "iteration 900 / 1900: loss 2.116196\n",
            "iteration 1000 / 1900: loss 2.147279\n",
            "iteration 1100 / 1900: loss 2.124178\n",
            "iteration 1200 / 1900: loss 2.065438\n",
            "iteration 1300 / 1900: loss 2.176382\n",
            "iteration 1400 / 1900: loss 2.110106\n",
            "iteration 1500 / 1900: loss 2.104144\n",
            "iteration 1600 / 1900: loss 2.164510\n",
            "iteration 1700 / 1900: loss 2.094802\n",
            "iteration 1800 / 1900: loss 2.107063\n",
            "iteration 0 / 1900: loss 1533.357756\n",
            "iteration 100 / 1900: loss 2.187807\n",
            "iteration 200 / 1900: loss 2.101120\n",
            "iteration 300 / 1900: loss 2.135853\n",
            "iteration 400 / 1900: loss 2.156444\n",
            "iteration 500 / 1900: loss 2.134890\n",
            "iteration 600 / 1900: loss 2.203343\n",
            "iteration 700 / 1900: loss 2.137576\n",
            "iteration 800 / 1900: loss 2.122619\n",
            "iteration 900 / 1900: loss 2.145382\n",
            "iteration 1000 / 1900: loss 2.168636\n",
            "iteration 1100 / 1900: loss 2.161077\n",
            "iteration 1200 / 1900: loss 2.143751\n",
            "iteration 1300 / 1900: loss 2.113140\n",
            "iteration 1400 / 1900: loss 2.154699\n",
            "iteration 1500 / 1900: loss 2.194307\n",
            "iteration 1600 / 1900: loss 2.133465\n",
            "iteration 1700 / 1900: loss 2.155266\n",
            "iteration 1800 / 1900: loss 2.127444\n",
            "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.167388 val accuracy: 0.162000\n",
            "lr 1.000000e-08 reg 1.000000e+04 train accuracy: 0.172408 val accuracy: 0.173000\n",
            "lr 1.000000e-08 reg 2.500000e+04 train accuracy: 0.189224 val accuracy: 0.189000\n",
            "lr 1.000000e-08 reg 3.500000e+04 train accuracy: 0.208265 val accuracy: 0.217000\n",
            "lr 1.000000e-08 reg 5.000000e+04 train accuracy: 0.252020 val accuracy: 0.271000\n",
            "lr 1.000000e-07 reg 5.000000e+03 train accuracy: 0.351000 val accuracy: 0.370000\n",
            "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.356755 val accuracy: 0.377000\n",
            "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.329694 val accuracy: 0.342000\n",
            "lr 1.000000e-07 reg 3.500000e+04 train accuracy: 0.315429 val accuracy: 0.331000\n",
            "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.307694 val accuracy: 0.332000\n",
            "lr 5.000000e-07 reg 5.000000e+03 train accuracy: 0.374184 val accuracy: 0.392000\n",
            "lr 5.000000e-07 reg 1.000000e+04 train accuracy: 0.355796 val accuracy: 0.370000\n",
            "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.327082 val accuracy: 0.342000\n",
            "lr 5.000000e-07 reg 3.500000e+04 train accuracy: 0.319449 val accuracy: 0.332000\n",
            "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.301551 val accuracy: 0.315000\n",
            "lr 1.000000e-06 reg 5.000000e+03 train accuracy: 0.371429 val accuracy: 0.378000\n",
            "lr 1.000000e-06 reg 1.000000e+04 train accuracy: 0.348347 val accuracy: 0.357000\n",
            "lr 1.000000e-06 reg 2.500000e+04 train accuracy: 0.313571 val accuracy: 0.328000\n",
            "lr 1.000000e-06 reg 3.500000e+04 train accuracy: 0.289918 val accuracy: 0.304000\n",
            "lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.295143 val accuracy: 0.312000\n",
            "best validation accuracy achieved during cross-validation: 0.392000\n"
          ]
        }
      ],
      "source": [
        "# Use the validation set to tune hyperparameters (regularization strength and\n",
        "# learning rate). You should experiment with different ranges for the learning\n",
        "# rates and regularization strengths; if you are careful you should be able to\n",
        "# get a classification accuracy of over 0.35 on the validation set.\n",
        "\n",
        "from cs231n.classifiers import Softmax\n",
        "results = {}\n",
        "best_val = -1\n",
        "best_softmax = None\n",
        "\n",
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Use the validation set to set the learning rate and regularization strength. #\n",
        "# This should be identical to the validation that you did for the SVM; save    #\n",
        "# the best trained softmax classifer in best_softmax.                          #\n",
        "################################################################################\n",
        "\n",
        "# Provided as a reference. You may or may not want to change these hyperparameters\n",
        "learning_rates = [1e-8, 1e-7, 5e-7, 1e-6]\n",
        "regularization_strengths = [5e3, 1e4, 2.5e4, 3.5e4, 5e4]\n",
        "\n",
        "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "for lr in learning_rates:\n",
        "  for rs in regularization_strengths:\n",
        "    s_max = Softmax()\n",
        "    loss_hist = s_max.train(X_train, y_train, learning_rate=lr, reg=rs, \n",
        "                          num_iters=1900, verbose=True)\n",
        "    y_train_pred = s_max.predict(X_train)\n",
        "    train_acc = np.mean(y_train == y_train_pred)\n",
        "    y_val_pred = s_max.predict(X_val)\n",
        "    val_acc = np.mean(y_val == y_val_pred)\n",
        "    results[(lr, rs)] = (train_acc, val_acc)\n",
        "    if val_acc > best_val:\n",
        "      best_val = val_acc\n",
        "      best_softmax = s_max\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    \n",
        "# Print out results.\n",
        "for lr, reg in sorted(results):\n",
        "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
        "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
        "                lr, reg, train_accuracy, val_accuracy))\n",
        "    \n",
        "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "test",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea5ad2e-5058-402d-99a0-b5252ac90b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax on raw pixels final test set accuracy: 0.372000\n"
          ]
        }
      ],
      "source": [
        "# evaluate on test set\n",
        "# Evaluate the best softmax on test set\n",
        "y_test_pred = best_softmax.predict(X_test)\n",
        "test_accuracy = np.mean(y_test == y_test_pred)\n",
        "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "pdf-inline"
        ],
        "id": "rbp8ZLjQq47A"
      },
      "source": [
        "**Inline Question 2** - *True or False*\n",
        "\n",
        "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
        "\n",
        "$\\color{blue}{\\textit Your Answer:}$ True\n",
        "\n",
        "\n",
        "$\\color{blue}{\\textit Your Explanation:}$ In softmax, every change in the data can impact the loss, whereas in SVM, as long as the score per class is above some threshold, the loss is the same.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cCa4D2g1q47B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "5e7e6acd-c50c-4c07-d90f-f9f5ece8d2ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualize the learned weights for each class\n",
        "w = best_softmax.W[:-1,:] # strip out the bias\n",
        "w = w.reshape(32, 32, 3, 10)\n",
        "\n",
        "w_min, w_max = np.min(w), np.max(w)\n",
        "\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    \n",
        "    # Rescale the weights to be between 0 and 255\n",
        "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
        "    plt.imshow(wimg.astype('uint8'))\n",
        "    plt.axis('off')\n",
        "    plt.title(classes[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAADisz_q47B"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "softmax.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}